---
phase: 06-memory-foundation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - core/memory/database.py
  - core/memory/schema.py
autonomous: true

must_haves:
  truths:
    - "Database can store and retrieve facts reliably"
    - "Full-text search returns relevant results from stored facts"
    - "Entity linking works (facts can be associated with entities)"
    - "Preferences can be stored and queried per-user"
    - "Sessions can be tracked per-platform per-user"
  artifacts:
    - path: "core/memory/schema.py"
      provides: "SQL schema definitions"
      exports: ["SCHEMA_SQL", "INDEXES_SQL", "TRIGGERS_SQL"]
    - path: "core/memory/database.py"
      provides: "Database connection and initialization"
      exports: ["init_database", "get_connection", "DatabaseManager"]
  key_links:
    - from: "core/memory/database.py"
      to: "~/.lifeos/memory/jarvis.db"
      via: "sqlite3.connect"
      pattern: "connect.*jarvis\\.db"
---

<objective>
Create the SQLite database schema with all required tables for the Clawdbot memory architecture: facts, entities, entity_mentions, preferences, sessions, facts_fts (FTS5), and fact_embeddings.

Purpose: Establish the structured storage layer that enables fast queries, full-text search, and links to PostgreSQL vector embeddings. WAL mode enables concurrent access from multiple bot processes.

Output:
- core/memory/schema.py with SQL schema definitions
- core/memory/database.py with connection management and initialization
- jarvis.db created at ~/.lifeos/memory/ with all tables
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/memory-integration/PROJECT.md
@.planning/memory-integration/phases/06-memory-foundation/06-RESEARCH.md

Schema from PROJECT.md:
```sql
-- Core facts table
CREATE TABLE facts (
    id INTEGER PRIMARY KEY,
    content TEXT NOT NULL,
    context TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    source TEXT,  -- 'telegram', 'treasury', 'x', 'bags_intel'
    confidence REAL DEFAULT 1.0
);

-- Entities (tokens, users, strategies)
CREATE TABLE entities (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE NOT NULL,
    type TEXT NOT NULL,  -- 'token', 'user', 'strategy'
    summary TEXT,
    last_updated DATETIME
);

-- Entity mentions (linking)
CREATE TABLE entity_mentions (
    fact_id INTEGER REFERENCES facts(id),
    entity_id INTEGER REFERENCES entities(id),
    PRIMARY KEY (fact_id, entity_id)
);

-- User preferences with confidence
CREATE TABLE preferences (
    id INTEGER PRIMARY KEY,
    user TEXT NOT NULL,
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    confidence REAL DEFAULT 0.5,
    evidence_count INTEGER DEFAULT 1,
    last_updated DATETIME,
    UNIQUE(user, key)
);

-- Sessions (per-user, per-platform)
CREATE TABLE sessions (
    id TEXT PRIMARY KEY,  -- UUID
    user TEXT NOT NULL,
    platform TEXT NOT NULL,  -- 'telegram', 'x', 'api'
    started_at DATETIME,
    ended_at DATETIME,
    metadata TEXT  -- JSON
);

-- FTS5 for full-text search
CREATE VIRTUAL TABLE facts_fts USING fts5(
    content,
    context,
    content=facts,
    content_rowid=id
);

-- Vector embeddings (link to PostgreSQL)
CREATE TABLE fact_embeddings (
    fact_id INTEGER PRIMARY KEY REFERENCES facts(id),
    postgres_memory_id INTEGER  -- Links to archival_memory.id
);
```

From RESEARCH.md:
- Use WAL mode for concurrent access from 5 bots
- Use `tokenize='porter unicode61'` for better search
- Create triggers to keep FTS5 synced with facts table
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create SQL schema definitions</name>
  <files>core/memory/schema.py</files>
  <action>
Create schema.py with all SQL definitions as constants.

```python
"""SQLite schema definitions for Jarvis memory system."""

# Core tables schema
SCHEMA_SQL = """
-- Facts table: stores all memory entries
CREATE TABLE IF NOT EXISTS facts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    content TEXT NOT NULL,
    context TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    source TEXT CHECK(source IN ('telegram', 'treasury', 'x', 'bags_intel', 'buy_tracker', 'system', NULL)),
    confidence REAL DEFAULT 1.0 CHECK(confidence >= 0.0 AND confidence <= 1.0),
    is_active INTEGER DEFAULT 1  -- Soft delete flag (append-only architecture)
);

-- Entities table: tokens, users, strategies
CREATE TABLE IF NOT EXISTS entities (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT UNIQUE NOT NULL,
    type TEXT NOT NULL CHECK(type IN ('token', 'user', 'strategy', 'platform', 'other')),
    summary TEXT,
    metadata TEXT,  -- JSON for additional properties
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Entity mentions: links facts to entities (many-to-many)
CREATE TABLE IF NOT EXISTS entity_mentions (
    fact_id INTEGER NOT NULL,
    entity_id INTEGER NOT NULL,
    mention_type TEXT DEFAULT 'reference',  -- 'reference', 'subject', 'outcome'
    PRIMARY KEY (fact_id, entity_id),
    FOREIGN KEY (fact_id) REFERENCES facts(id) ON DELETE CASCADE,
    FOREIGN KEY (entity_id) REFERENCES entities(id) ON DELETE CASCADE
);

-- User preferences with confidence evolution
CREATE TABLE IF NOT EXISTS preferences (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    user TEXT NOT NULL,
    key TEXT NOT NULL,
    value TEXT NOT NULL,
    confidence REAL DEFAULT 0.5 CHECK(confidence >= 0.0 AND confidence <= 1.0),
    evidence_count INTEGER DEFAULT 1,
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    last_updated DATETIME DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user, key)
);

-- Sessions: per-user, per-platform tracking
CREATE TABLE IF NOT EXISTS sessions (
    id TEXT PRIMARY KEY,  -- UUID
    user TEXT NOT NULL,
    platform TEXT NOT NULL CHECK(platform IN ('telegram', 'x', 'api', 'voice', 'system')),
    started_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    ended_at DATETIME,
    metadata TEXT,  -- JSON: conversation context, current task, etc.
    is_active INTEGER DEFAULT 1
);

-- User identity linking: maps platform IDs to canonical user
CREATE TABLE IF NOT EXISTS user_identities (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    canonical_user TEXT NOT NULL,  -- Internal user ID (e.g., 'lucid')
    platform TEXT NOT NULL,
    platform_user_id TEXT NOT NULL,  -- Platform-specific ID
    display_name TEXT,
    linked_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(platform, platform_user_id)
);

-- Fact embeddings: links SQLite facts to PostgreSQL archival_memory
CREATE TABLE IF NOT EXISTS fact_embeddings (
    fact_id INTEGER PRIMARY KEY,
    postgres_memory_id INTEGER,  -- Links to archival_memory.id in PostgreSQL
    embedding_model TEXT DEFAULT 'bge-large-en-v1.5',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (fact_id) REFERENCES facts(id) ON DELETE CASCADE
);

-- Schema version for migrations
CREATE TABLE IF NOT EXISTS schema_version (
    version INTEGER PRIMARY KEY,
    applied_at DATETIME DEFAULT CURRENT_TIMESTAMP,
    description TEXT
);
"""

# FTS5 virtual table for full-text search
FTS5_SQL = """
-- FTS5 virtual table with external content (synced via triggers)
CREATE VIRTUAL TABLE IF NOT EXISTS facts_fts USING fts5(
    content,
    context,
    content=facts,
    content_rowid=id,
    tokenize='porter unicode61'
);
"""

# Triggers to keep FTS5 synced with facts table
TRIGGERS_SQL = """
-- Insert trigger: add to FTS5 when fact is inserted
CREATE TRIGGER IF NOT EXISTS facts_fts_insert AFTER INSERT ON facts BEGIN
    INSERT INTO facts_fts(rowid, content, context)
    VALUES (new.id, new.content, new.context);
END;

-- Delete trigger: remove from FTS5 when fact is deleted
CREATE TRIGGER IF NOT EXISTS facts_fts_delete AFTER DELETE ON facts BEGIN
    DELETE FROM facts_fts WHERE rowid = old.id;
END;

-- Update trigger: update FTS5 when fact is modified
CREATE TRIGGER IF NOT EXISTS facts_fts_update AFTER UPDATE ON facts BEGIN
    DELETE FROM facts_fts WHERE rowid = old.id;
    INSERT INTO facts_fts(rowid, content, context)
    VALUES (new.id, new.content, new.context);
END;

-- Auto-update last_updated on entities
CREATE TRIGGER IF NOT EXISTS entities_updated AFTER UPDATE ON entities BEGIN
    UPDATE entities SET last_updated = CURRENT_TIMESTAMP WHERE id = new.id;
END;

-- Auto-update last_updated on preferences
CREATE TRIGGER IF NOT EXISTS preferences_updated AFTER UPDATE ON preferences BEGIN
    UPDATE preferences SET last_updated = CURRENT_TIMESTAMP WHERE id = new.id;
END;
"""

# Indexes for common query patterns
INDEXES_SQL = """
-- Facts indexes
CREATE INDEX IF NOT EXISTS idx_facts_timestamp ON facts(timestamp DESC);
CREATE INDEX IF NOT EXISTS idx_facts_source ON facts(source);
CREATE INDEX IF NOT EXISTS idx_facts_source_timestamp ON facts(source, timestamp DESC);
CREATE INDEX IF NOT EXISTS idx_facts_active ON facts(is_active) WHERE is_active = 1;

-- Entities indexes
CREATE INDEX IF NOT EXISTS idx_entities_type ON entities(type);
CREATE INDEX IF NOT EXISTS idx_entities_name_type ON entities(name, type);

-- Entity mentions indexes
CREATE INDEX IF NOT EXISTS idx_entity_mentions_entity ON entity_mentions(entity_id);

-- Preferences indexes
CREATE INDEX IF NOT EXISTS idx_preferences_user ON preferences(user);
CREATE INDEX IF NOT EXISTS idx_preferences_user_key ON preferences(user, key);

-- Sessions indexes
CREATE INDEX IF NOT EXISTS idx_sessions_user ON sessions(user);
CREATE INDEX IF NOT EXISTS idx_sessions_platform ON sessions(platform);
CREATE INDEX IF NOT EXISTS idx_sessions_active ON sessions(is_active) WHERE is_active = 1;

-- User identities indexes
CREATE INDEX IF NOT EXISTS idx_user_identities_canonical ON user_identities(canonical_user);
CREATE INDEX IF NOT EXISTS idx_user_identities_platform ON user_identities(platform, platform_user_id);

-- Fact embeddings indexes
CREATE INDEX IF NOT EXISTS idx_fact_embeddings_postgres ON fact_embeddings(postgres_memory_id);
"""

# Initial schema version
INITIAL_VERSION_SQL = """
INSERT OR IGNORE INTO schema_version (version, description)
VALUES (1, 'Initial schema: facts, entities, preferences, sessions, FTS5');
"""

# All SQL in order
ALL_SQL = [SCHEMA_SQL, FTS5_SQL, TRIGGERS_SQL, INDEXES_SQL, INITIAL_VERSION_SQL]
```
  </action>
  <verify>
```bash
python -c "from core.memory.schema import SCHEMA_SQL, FTS5_SQL, TRIGGERS_SQL, INDEXES_SQL, ALL_SQL; print(f'Schema length: {len(SCHEMA_SQL)} chars'); print(f'Total SQL statements: {len(ALL_SQL)}')"
```
Should print schema length and statement count without errors.
  </verify>
  <done>schema.py exports SCHEMA_SQL, FTS5_SQL, TRIGGERS_SQL, INDEXES_SQL, and ALL_SQL</done>
</task>

<task type="auto">
  <name>Task 2: Create database connection manager</name>
  <files>core/memory/database.py</files>
  <action>
Create database.py with connection management and initialization.

```python
"""SQLite database connection and initialization for Jarvis memory system."""
import sqlite3
import threading
from contextlib import contextmanager
from pathlib import Path
from typing import Optional, Generator

from .config import get_config, MemoryConfig
from .schema import ALL_SQL


class DatabaseManager:
    """
    Thread-safe SQLite database manager with WAL mode.

    Provides connection pooling and ensures proper initialization.
    """

    _instance: Optional["DatabaseManager"] = None
    _lock = threading.Lock()

    def __init__(self, db_path: Optional[Path] = None):
        """
        Initialize database manager.

        Args:
            db_path: Path to database file. Uses config default if not provided.
        """
        if db_path is None:
            config = get_config()
            db_path = config.db_path

        self.db_path = db_path
        self._local = threading.local()
        self._initialized = False

    @classmethod
    def get_instance(cls, db_path: Optional[Path] = None) -> "DatabaseManager":
        """Get or create singleton instance."""
        with cls._lock:
            if cls._instance is None:
                cls._instance = cls(db_path)
            return cls._instance

    def _get_connection(self) -> sqlite3.Connection:
        """Get thread-local connection."""
        if not hasattr(self._local, "connection") or self._local.connection is None:
            # Ensure parent directory exists
            self.db_path.parent.mkdir(parents=True, exist_ok=True)

            conn = sqlite3.connect(
                str(self.db_path),
                timeout=30.0,  # 30 second timeout for busy database
                check_same_thread=False,  # Allow multi-thread access
            )

            # Enable WAL mode for concurrent access
            conn.execute("PRAGMA journal_mode=WAL")

            # Performance tuning
            conn.execute("PRAGMA synchronous=NORMAL")  # Safe with WAL
            conn.execute("PRAGMA cache_size=-64000")  # 64MB cache
            conn.execute("PRAGMA temp_store=MEMORY")  # Temp tables in RAM
            conn.execute("PRAGMA busy_timeout=5000")  # 5 second busy wait

            # Enable foreign keys
            conn.execute("PRAGMA foreign_keys=ON")

            # Row factory for dict-like access
            conn.row_factory = sqlite3.Row

            self._local.connection = conn

        return self._local.connection

    def init_schema(self) -> None:
        """Initialize database schema if not already done."""
        if self._initialized:
            return

        with self._lock:
            if self._initialized:
                return

            conn = self._get_connection()

            # Execute all schema SQL
            for sql in ALL_SQL:
                conn.executescript(sql)

            conn.commit()
            self._initialized = True

    @contextmanager
    def connection(self) -> Generator[sqlite3.Connection, None, None]:
        """
        Context manager for database connection.

        Automatically initializes schema on first use.

        Example:
            with db.connection() as conn:
                conn.execute("SELECT * FROM facts")
        """
        if not self._initialized:
            self.init_schema()

        conn = self._get_connection()
        try:
            yield conn
        except Exception:
            conn.rollback()
            raise

    @contextmanager
    def transaction(self) -> Generator[sqlite3.Connection, None, None]:
        """
        Context manager for database transaction.

        Commits on success, rolls back on exception.

        Example:
            with db.transaction() as conn:
                conn.execute("INSERT INTO facts ...")
        """
        if not self._initialized:
            self.init_schema()

        conn = self._get_connection()
        try:
            yield conn
            conn.commit()
        except Exception:
            conn.rollback()
            raise

    def close(self) -> None:
        """Close thread-local connection."""
        if hasattr(self._local, "connection") and self._local.connection is not None:
            self._local.connection.close()
            self._local.connection = None

    def get_schema_version(self) -> int:
        """Get current schema version."""
        with self.connection() as conn:
            result = conn.execute(
                "SELECT MAX(version) FROM schema_version"
            ).fetchone()
            return result[0] if result and result[0] else 0


# Module-level convenience functions

_db_manager: Optional[DatabaseManager] = None


def init_database(db_path: Optional[Path] = None) -> DatabaseManager:
    """
    Initialize the database and return manager instance.

    This is the primary entry point for database setup.

    Args:
        db_path: Optional path override. Uses ~/.lifeos/memory/jarvis.db by default.

    Returns:
        DatabaseManager instance ready for use.
    """
    global _db_manager

    if _db_manager is None:
        _db_manager = DatabaseManager.get_instance(db_path)

    _db_manager.init_schema()
    return _db_manager


def get_connection() -> sqlite3.Connection:
    """
    Get a database connection.

    Initializes database if needed.

    Returns:
        sqlite3.Connection with WAL mode enabled.
    """
    if _db_manager is None:
        init_database()

    return _db_manager._get_connection()


def get_db_manager() -> DatabaseManager:
    """Get the database manager instance."""
    global _db_manager
    if _db_manager is None:
        _db_manager = init_database()
    return _db_manager
```

Also update core/memory/__init__.py to include new exports:

```python
"""Jarvis Memory System - Clawdbot-inspired dual-layer memory architecture."""
from .config import MemoryConfig, get_config
from .workspace import init_workspace, get_memory_path, get_daily_log_path, MEMORY_ROOT
from .database import init_database, get_connection, get_db_manager, DatabaseManager
from .schema import SCHEMA_SQL, FTS5_SQL, TRIGGERS_SQL, INDEXES_SQL

__all__ = [
    # Config
    "MemoryConfig",
    "get_config",
    # Workspace
    "init_workspace",
    "get_memory_path",
    "get_daily_log_path",
    "MEMORY_ROOT",
    # Database
    "init_database",
    "get_connection",
    "get_db_manager",
    "DatabaseManager",
    # Schema
    "SCHEMA_SQL",
    "FTS5_SQL",
    "TRIGGERS_SQL",
    "INDEXES_SQL",
]
```
  </action>
  <verify>
```bash
python -c "
from core.memory import init_workspace, init_database, get_db_manager

# Initialize workspace first
root = init_workspace()
print(f'Workspace: {root}')

# Initialize database
db = init_database()
print(f'Database: {db.db_path}')
print(f'Schema version: {db.get_schema_version()}')

# Verify tables exist
with db.connection() as conn:
    tables = conn.execute(\"\"\"
        SELECT name FROM sqlite_master
        WHERE type='table' AND name NOT LIKE 'sqlite_%'
        ORDER BY name
    \"\"\").fetchall()
    print(f'Tables: {[t[0] for t in tables]}')

    # Check WAL mode
    mode = conn.execute('PRAGMA journal_mode').fetchone()[0]
    print(f'Journal mode: {mode}')

print('SUCCESS')
"
```
Should show database path, schema version 1, all tables, and WAL mode.
  </verify>
  <done>
- jarvis.db created at ~/.lifeos/memory/jarvis.db
- WAL mode enabled for concurrent access
- All tables created (facts, entities, entity_mentions, preferences, sessions, user_identities, fact_embeddings, schema_version)
- FTS5 virtual table facts_fts created with triggers
- All indexes created for query performance
- DatabaseManager provides thread-safe connection pooling
  </done>
</task>

</tasks>

<verification>
1. Verify database file exists:
```bash
ls -la ~/.lifeos/memory/jarvis.db
```

2. Verify WAL files (indicates WAL mode is active):
```bash
ls -la ~/.lifeos/memory/jarvis.db*
```
Should show jarvis.db, jarvis.db-wal, jarvis.db-shm

3. Verify all tables:
```bash
python -c "
from core.memory import init_database
db = init_database()
with db.connection() as conn:
    for row in conn.execute('SELECT name FROM sqlite_master WHERE type=\"table\" ORDER BY name'):
        print(row[0])
"
```

4. Verify FTS5 works:
```bash
python -c "
from core.memory import init_database
db = init_database()
with db.transaction() as conn:
    # Insert test fact
    conn.execute('INSERT INTO facts (content, context, source) VALUES (?, ?, ?)',
                 ('Test fact about KR8TIV token', 'bags.fm graduation', 'treasury'))
    # Search via FTS5
    results = conn.execute('SELECT * FROM facts_fts WHERE facts_fts MATCH ?', ('KR8TIV',)).fetchall()
    print(f'FTS5 search found: {len(results)} results')
    # Cleanup
    conn.execute('DELETE FROM facts WHERE content LIKE ?', ('Test fact%',))
print('FTS5 working!')
"
```
</verification>

<success_criteria>
- jarvis.db file exists at ~/.lifeos/memory/jarvis.db
- WAL mode is enabled (PRAGMA journal_mode returns 'wal')
- All 8 tables exist: facts, entities, entity_mentions, preferences, sessions, user_identities, fact_embeddings, schema_version
- facts_fts virtual table exists and FTS5 searches work
- Triggers fire correctly (insert into facts auto-populates facts_fts)
- Schema version is 1
- DatabaseManager provides thread-safe connections
- Foreign keys are enforced
</success_criteria>

<output>
After completion, create `.planning/memory-integration/phases/06-memory-foundation/06-02-SUMMARY.md`
</output>
