---
phase: 08-reflect-intelligence
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - core/memory/reflect.py
  - core/memory/entity_profiles.py
autonomous: true

must_haves:
  truths:
    - "Entity summaries auto-update during daily reflection"
    - "Only entities with new facts since last reflect get updated"
    - "Entity profile markdown files preserve historical summaries"
    - "LLM synthesis produces actionable 3-5 bullet point insights"
    - "Entity relationships tracked (token → strategy, user → preferences)"
  artifacts:
    - path: "core/memory/reflect.py"
      provides: "update_entity_summaries() and track_entity_relationships() functions"
      exports: ["update_entity_summaries", "track_entity_relationships"]
      contains: "def update_entity_summaries"
  key_links:
    - from: "core/memory/reflect.py"
      to: "core/memory/summarize.py"
      via: "synthesize_entity_insights for LLM summaries"
      pattern: "synthesize_entity_insights"
    - from: "core/memory/reflect.py"
      to: "core/memory/entity_profiles.py"
      via: "update_entity_profile for markdown persistence"
      pattern: "update_entity_profile"
---

<objective>
Add entity summary auto-update to daily reflection. When reflect_daily() runs, entities with new facts since last reflection get updated summaries synthesized by LLM and persisted to markdown profiles.

Purpose: Keep entity profiles current with evolving knowledge, enabling bots to query up-to-date token/user/strategy intelligence.

Output:
- `update_entity_summaries()` function in reflect.py
- Integration into reflect_daily() flow
- Entity profile markdown files with rolling summaries
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/memory-integration/PROJECT.md
@.planning/memory-integration/STATE.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-RESEARCH.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-01-SUMMARY.md
@.planning/memory-integration/phases/07-retain-recall-functions/07-02-SUMMARY.md
@core/memory/entity_profiles.py
@core/memory/summarize.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement update_entity_summaries function</name>
  <files>core/memory/reflect.py</files>
  <action>
Add `update_entity_summaries()` function to `core/memory/reflect.py`:

1. **update_entity_summaries(since_time: datetime) -> Dict[str, int]**
   - Query entities with new facts since `since_time` using:
     ```sql
     SELECT DISTINCT e.id, e.name, e.type
     FROM entities e
     JOIN entity_mentions em ON e.id = em.entity_id
     JOIN facts f ON em.fact_id = f.id
     WHERE f.timestamp > ?
     ```
   - For each entity with new facts:
     a. Get recent facts (last 100) mentioning this entity using get_entity_facts()
     b. Score facts by recency + importance:
        - Recency: `2^(-hours_ago / (7 * 24))` (7-day half-life)
        - Importance: context weight * confidence
        - Context weights: trade_outcome=1.0, user_preference=0.8, graduation_pattern=0.7, general=0.5
     c. Take top 20 facts by combined score
     d. Call synthesize_entity_insights() to generate summary
     e. Call update_entity_profile() to persist new summary to markdown
        - Pass update_summary=True, new_summary=synthesis
   - Return dict: {entities_updated: N, entities_skipped: M}
   - Log each entity update

2. Handle edge cases:
   - Entity with no entity_type defaults to "other"
   - Facts with missing confidence default to 0.5
   - Empty synthesis returns "No significant activity" placeholder

3. Use fire_and_forget pattern for non-blocking execution:
   - Import from core.async_utils import fire_and_forget
   - Wrap in async if called from async context

Example scoring:
```python
now = datetime.utcnow()
hours_ago = (now - fact_time).total_seconds() / 3600
recency_score = 2 ** (-hours_ago / (7 * 24))  # 7-day half-life
importance = context_weights.get(fact['context'], 0.5) * fact.get('confidence', 0.5)
total_score = recency_score * importance
```
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -c "
from core.memory.reflect import update_entity_summaries
import inspect
sig = inspect.signature(update_entity_summaries)
print(f'update_entity_summaries signature: {sig}')
print('Function exists and is importable')
"
```
  </verify>
  <done>
update_entity_summaries() exists, accepts since_time parameter, and returns dict with update counts.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate entity updates into reflect_daily</name>
  <files>core/memory/reflect.py</files>
  <action>
Modify `reflect_daily()` to call `update_entity_summaries()`:

1. After appending synthesis to memory.md, call:
   ```python
   # Get last reflect time for entity filtering
   state = get_reflect_state()
   last_reflect = state.get("last_reflect_time")
   if last_reflect:
       since_time = datetime.fromisoformat(last_reflect)
   else:
       # First run: only update entities from yesterday
       since_time = yesterday_start

   # Update entity summaries (non-blocking)
   from core.async_utils import fire_and_forget
   import asyncio

   async def _update_entities():
       return update_entity_summaries(since_time)

   # Run in background if event loop exists, else sync
   try:
       loop = asyncio.get_running_loop()
       fire_and_forget(_update_entities(), name="update_entity_summaries")
   except RuntimeError:
       # No event loop, run synchronously
       entity_stats = update_entity_summaries(since_time)
       logger.info(f"Entity summaries updated: {entity_stats}")
   ```

2. Add entity_updates_queued: True to the return stats dict

3. Ensure update_entity_summaries can run both sync and async:
   - If called directly (sync), execute immediately
   - If in async context, use fire_and_forget for non-blocking

4. Log the entity update execution
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -c "
from core.memory.reflect import reflect_daily

# Verify entity updates are integrated
import inspect
source = inspect.getsource(reflect_daily)
assert 'update_entity_summaries' in source, 'Missing entity update call'
print('Entity updates integrated into reflect_daily')
"
```
  </verify>
  <done>
reflect_daily() calls update_entity_summaries() after fact synthesis. Entity updates run in background (non-blocking).
  </done>
</task>

<task type="auto">
  <name>Task 3: Test entity summary auto-update flow</name>
  <files>core/memory/reflect.py</files>
  <action>
Test the entity summary update flow:

1. First, ensure an entity exists with facts:
```python
from core.memory.retain import retain_fact
from core.memory.entity_profiles import create_entity_profile, get_entity_profile

# Create test entity if needed
create_entity_profile("TEST_REFLECT_TOKEN", "token", summary="Test token for reflection")

# Store facts mentioning the entity
retain_fact(
    content="TEST_REFLECT_TOKEN traded at +20% profit",
    context="trade_outcome",
    source="treasury_trading",
    entities=["@TEST_REFLECT_TOKEN"]
)
retain_fact(
    content="TEST_REFLECT_TOKEN showing strong momentum",
    context="market_observation",
    source="bags_intel",
    entities=["@TEST_REFLECT_TOKEN"]
)
print("Test facts stored")
```

2. Test update_entity_summaries() directly:
```python
from core.memory.reflect import update_entity_summaries
from datetime import datetime, timedelta

# Update entities from last 24 hours
since_time = datetime.utcnow() - timedelta(hours=24)
result = update_entity_summaries(since_time)
print(f"Entity update result: {result}")
```

3. Verify entity profile was updated:
```python
from core.memory.entity_profiles import get_entity_profile

profile = get_entity_profile("TEST_REFLECT_TOKEN")
if profile:
    print(f"Profile summary: {profile.get('summary', 'N/A')[:100]}...")
    print(f"Profile has content: {len(profile.get('profile_content', '')) > 0}")
```

Fix any issues found during testing.
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -c "
from core.memory.reflect import update_entity_summaries
from datetime import datetime, timedelta

# Verify function executes without error
since_time = datetime.utcnow() - timedelta(hours=24)
result = update_entity_summaries(since_time)
print(f'Result: {result}')
assert 'entities_updated' in result or isinstance(result, dict), 'Invalid return type'
print('Entity summary update verified')
"
```
  </verify>
  <done>
update_entity_summaries() executes without errors, processes entities with recent facts, and updates their markdown profiles via synthesized summaries.
  </done>
</task>

<task type="auto">
  <name>Task 4: Track entity relationships</name>
  <files>core/memory/reflect.py, core/memory/entity_profiles.py</files>
  <action>
Implement entity relationship tracking to satisfy ENT-006:

1. **Add track_entity_relationships(since_time: datetime) -> Dict[str, int]** to `core/memory/reflect.py`:
   - Query co-occurring entities in facts:
     ```sql
     SELECT
         em1.entity_name as entity1,
         em1.entity_type as type1,
         em2.entity_name as entity2,
         em2.entity_type as type2,
         COUNT(*) as co_occurrence_count
     FROM entity_mentions em1
     JOIN entity_mentions em2 ON em1.fact_id = em2.fact_id
     JOIN facts f ON em1.fact_id = f.id
     WHERE em1.entity_id < em2.entity_id  -- avoid duplicates
     AND f.timestamp > ?
     GROUP BY em1.entity_name, em1.entity_type, em2.entity_name, em2.entity_type
     HAVING COUNT(*) >= 2  -- minimum 2 co-occurrences
     ```

2. **Build relationship mapping**:
   - Token → Strategy relationships: When token and strategy appear in same trade_outcome fact
   - User → Preference relationships: When user and preference key appear in same user_preference fact
   - Store as dict: `{entity_name: {"related_to": [(other_entity, type, count), ...]}}`

3. **Update entity profiles with relationships**:
   - For each entity with new relationships:
     - Read current profile markdown
     - Append "## Relationships" section if missing
     - Add relationship entries: `- **{type}**: {entity_name} ({count} occurrences)`
     - Write updated markdown back to profile file

4. **Integrate into reflect_daily()**:
   ```python
   # Step 5: Track entity relationships
   rel_stats = track_entity_relationships(yesterday_start)
   logger.info(f"Entity relationships tracked: {rel_stats}")
   ```

5. Return stats: `{relationships_tracked: N, entities_updated: M}`

Example relationships output in profile:
```markdown
## Relationships

**Related Strategies**:
- momentum_breakout (12 occurrences)
- volume_spike (8 occurrences)

**Related Tokens**:
- BONK (5 co-trades)
- WIF (3 co-trades)
```
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -c "
from core.memory.reflect import track_entity_relationships
import inspect
sig = inspect.signature(track_entity_relationships)
print(f'track_entity_relationships signature: {sig}')

# Verify integration
from core.memory.reflect import reflect_daily
source = inspect.getsource(reflect_daily)
assert 'track_entity_relationships' in source, 'Missing relationship tracking'
print('Entity relationship tracking integrated')
"
```
  </verify>
  <done>
track_entity_relationships() exists, queries co-occurring entities, builds token→strategy and user→preference mappings, updates entity profiles with relationship sections. ENT-006 satisfied.
  </done>
</task>

</tasks>

<verification>
All verification steps must pass:

1. update_entity_summaries() exists in reflect.py
2. Function accepts since_time parameter
3. Function returns dict with update statistics
4. reflect_daily() integrates entity update call
5. Entity profile markdown files get updated with new summaries
6. track_entity_relationships() exists in reflect.py
7. Entity relationships persisted to profile markdown files
</verification>

<success_criteria>
- update_entity_summaries() scores facts by recency + importance
- Top 20 facts per entity get synthesized via LLM
- Entity profile markdown files preserve historical summaries (append pattern)
- Integration with reflect_daily() uses fire_and_forget for non-blocking
- Entity relationships tracked via co-occurrence analysis (token → strategy, user → preferences)
- Requirements REF-003, ENT-005, and ENT-006 satisfied
</success_criteria>

<output>
After completion, create `.planning/memory-integration/phases/08-reflect-intelligence/08-02-SUMMARY.md`
</output>
