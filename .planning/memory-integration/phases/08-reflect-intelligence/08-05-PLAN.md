---
phase: 08-reflect-intelligence
plan: 05
type: execute
wave: 3
depends_on: ["08-01", "08-02", "08-03", "08-04"]
files_modified:
  - bots/supervisor.py
  - tests/integration/test_memory_reflect.py
autonomous: true

must_haves:
  truths:
    - "Daily reflect job runs automatically at 3 AM UTC"
    - "Weekly summary job runs automatically on Sundays at 4 AM UTC"
    - "Scheduled jobs do not block other bot operations"
    - "Daily reflect completes in <5 minutes (PERF-002)"
    - "Memory database stays under 500MB with 10K+ facts (PERF-003)"
  artifacts:
    - path: "bots/supervisor.py"
      provides: "Memory reflect job registration"
      contains: "memory_daily_reflect"
    - path: "tests/integration/test_memory_reflect.py"
      provides: "Integration tests for Phase 8"
      min_lines: 100
  key_links:
    - from: "bots/supervisor.py"
      to: "core/memory/reflect.py"
      via: "ScheduledJob registration"
      pattern: "ScheduledJob.*reflect_daily"
    - from: "bots/supervisor.py"
      to: "core/memory/patterns.py"
      via: "ScheduledJob for weekly summary"
      pattern: "generate_weekly_summary"
---

<objective>
Register daily/weekly memory reflection jobs with supervisor scheduler and validate all Phase 8 requirements with integration tests.

Purpose: Complete Phase 8 by wiring all reflection components into the running system and verifying performance/quality requirements.

Output:
- Supervisor integration with scheduled reflect jobs
- Integration test suite validating PERF-002, PERF-003, and all REF requirements
- Verified end-to-end reflection flow
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/memory-integration/PROJECT.md
@.planning/memory-integration/STATE.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-RESEARCH.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-01-SUMMARY.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-02-SUMMARY.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-03-SUMMARY.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-04-SUMMARY.md
@bots/supervisor.py
@core/automation/scheduler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Register memory reflect jobs in supervisor</name>
  <files>bots/supervisor.py</files>
  <action>
Add memory reflection job registration to supervisor startup:

1. Find the supervisor startup/initialization section
2. Add imports:
   ```python
   from core.automation.scheduler import ActionScheduler, ScheduledJob, ScheduleType
   from core.memory.reflect import reflect_daily
   from core.memory.patterns import generate_weekly_summary
   ```

3. Create job registration function:
   ```python
   async def register_memory_reflect_jobs(scheduler: ActionScheduler):
       """
       Register daily/weekly memory reflection jobs.

       Jobs:
       - Daily reflect: 3 AM UTC every day
       - Weekly summary: 4 AM UTC every Sunday
       """
       # Daily reflection job
       daily_job = ScheduledJob(
           name="memory_daily_reflect",
           action=reflect_daily,
           schedule_type=ScheduleType.CRON,
           schedule_value="0 3 * * *",  # 3 AM UTC daily
           params={},
           enabled=True,
           retry_on_failure=True,
           timeout=300.0,  # 5 minutes max (PERF-002 requirement)
           tags=["memory", "reflect", "critical"]
       )
       scheduler.add_job(daily_job)
       logger.info("Registered daily memory reflect job (3 AM UTC)")

       # Weekly summary job
       weekly_job = ScheduledJob(
           name="memory_weekly_summary",
           action=generate_weekly_summary,
           schedule_type=ScheduleType.CRON,
           schedule_value="0 4 * * 0",  # 4 AM UTC every Sunday
           params={},
           enabled=True,
           retry_on_failure=True,
           timeout=600.0,  # 10 minutes max
           tags=["memory", "summary", "weekly"]
       )
       scheduler.add_job(weekly_job)
       logger.info("Registered weekly memory summary job (Sundays 4 AM UTC)")
   ```

4. Call during supervisor startup (in appropriate async context):
   - Locate where other scheduled jobs are registered
   - Add: `await register_memory_reflect_jobs(scheduler)`

5. Add kill switch environment variable check:
   ```python
   import os
   if os.environ.get("MEMORY_REFLECT_ENABLED", "true").lower() == "true":
       await register_memory_reflect_jobs(scheduler)
   else:
       logger.info("Memory reflection disabled via MEMORY_REFLECT_ENABLED=false")
   ```

If supervisor doesn't use ActionScheduler directly, adapt to existing pattern.
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -c "
# Verify imports work
from bots.supervisor import register_memory_reflect_jobs if hasattr(__import__('bots.supervisor'), 'register_memory_reflect_jobs') else None

# Check supervisor has memory reflect references
import inspect
from bots import supervisor
source = inspect.getsource(supervisor)
has_reflect = 'memory_daily_reflect' in source or 'reflect_daily' in source
print(f'Supervisor has reflect job registration: {has_reflect}')
"
```
  </verify>
  <done>
Supervisor registers memory_daily_reflect (3 AM UTC) and memory_weekly_summary (Sundays 4 AM UTC) jobs. Jobs have appropriate timeouts (5min/10min).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create integration test suite</name>
  <files>tests/integration/test_memory_reflect.py</files>
  <action>
Create `tests/integration/test_memory_reflect.py` with comprehensive tests:

```python
"""
Integration tests for Phase 8: Reflect & Intelligence.

Tests:
- REF-001: Daily reflect function runs
- REF-002: Core memory updated
- REF-003: Entity summaries auto-update
- REF-004: Preference confidence evolution
- REF-005: Log archival
- REF-006: Weekly pattern reports
- REF-007: Contradiction detection
- PERF-002: Daily reflect <5 minutes
- PERF-003: Database <500MB with 10K facts
"""

import pytest
import asyncio
import time
import os
from datetime import datetime, timedelta
from pathlib import Path

# Import memory components
from core.memory.reflect import (
    reflect_daily,
    get_reflect_state,
    update_entity_summaries,
    evolve_preference_confidence,
    archive_old_logs,
)
from core.memory.patterns import generate_weekly_summary, detect_contradictions
from core.memory.config import get_config
from core.memory.database import get_db
from core.memory.retain import retain_fact


class TestReflectCore:
    """Test core reflection functionality (REF-001, REF-002)."""

    def test_reflect_daily_returns_status(self):
        """REF-001: reflect_daily returns proper status dict."""
        result = reflect_daily()
        assert isinstance(result, dict)
        assert "status" in result
        assert result["status"] in ["completed", "skipped"]

    def test_reflect_state_persists(self):
        """REF-001: Reflect state saved to JSON file."""
        reflect_daily()
        state = get_reflect_state()
        assert isinstance(state, dict)
        # If completed, should have timestamp
        if state:
            assert "last_reflect_time" in state or state == {}

    def test_memory_md_updated_when_facts_exist(self):
        """REF-002: memory.md gets reflection sections."""
        # Store a fact first
        retain_fact(
            content="Integration test fact for reflection",
            context="test",
            source="integration_test",
            entities=[]
        )

        # Run reflection
        result = reflect_daily()

        # Check memory.md exists
        config = get_config()
        memory_path = config.memory_dir / "memory.md"
        assert memory_path.exists(), "memory.md should exist"


class TestEntitySummaryUpdate:
    """Test entity summary auto-update (REF-003, ENT-005)."""

    def test_update_entity_summaries_runs(self):
        """REF-003: Entity summaries update without error."""
        since = datetime.utcnow() - timedelta(days=1)
        result = update_entity_summaries(since)
        assert isinstance(result, dict)
        assert "entities_updated" in result or "error" not in result


class TestPreferenceEvolution:
    """Test preference confidence evolution (REF-004)."""

    def test_preference_confidence_bounds(self):
        """REF-004: Confidence stays within 0.1-0.95 bounds."""
        since = datetime.utcnow() - timedelta(days=7)
        result = evolve_preference_confidence(since)
        assert isinstance(result, dict)


class TestLogArchival:
    """Test log archival system (REF-005)."""

    def test_archive_creates_directory(self):
        """REF-005: Archives directory created."""
        result = archive_old_logs(archive_after_days=30)
        assert isinstance(result, dict)
        assert "archived" in result

        config = get_config()
        archives_dir = config.memory_dir / "memory" / "archives"
        assert archives_dir.exists(), "Archives directory should exist"


class TestWeeklyPatterns:
    """Test weekly pattern reports (REF-006)."""

    def test_weekly_summary_generates(self):
        """REF-006: Weekly summary generates without error."""
        result = generate_weekly_summary()
        assert isinstance(result, dict)
        # May have stats even with no data
        assert "week" in result or "error" not in str(result)


class TestContradictionDetection:
    """Test contradiction detection (REF-007)."""

    def test_detect_contradictions_returns_list(self):
        """REF-007: Contradiction detection returns list."""
        result = detect_contradictions()
        assert isinstance(result, list)


class TestPerformance:
    """Test performance requirements (PERF-002, PERF-003)."""

    def test_reflect_completes_under_5_minutes(self):
        """PERF-002: Daily reflect <5 minutes."""
        start = time.time()
        result = reflect_daily()
        duration = time.time() - start

        assert duration < 300, f"Reflect took {duration:.1f}s, should be <300s"
        print(f"Reflect completed in {duration:.1f}s")

    def test_database_size_reasonable(self):
        """PERF-003: Database under 500MB."""
        config = get_config()
        db_path = config.memory_dir / "jarvis.db"

        if db_path.exists():
            size_mb = db_path.stat().st_size / (1024 * 1024)
            assert size_mb < 500, f"Database is {size_mb:.1f}MB, should be <500MB"
            print(f"Database size: {size_mb:.2f}MB")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -m pytest tests/integration/test_memory_reflect.py -v --tb=short 2>&1 | head -50
```
  </verify>
  <done>
Integration test file created with tests for all Phase 8 requirements. Tests cover REF-001 through REF-007, PERF-002, PERF-003.
  </done>
</task>

<task type="auto">
  <name>Task 3: Run full test suite and validate</name>
  <files>tests/integration/test_memory_reflect.py</files>
  <action>
Run the complete test suite and fix any issues:

1. Run all Phase 8 tests:
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -m pytest tests/integration/test_memory_reflect.py -v --tb=long
```

2. Check for failures and fix issues:
   - If imports fail, verify module paths
   - If database errors, check schema compatibility
   - If timeouts, adjust test parameters

3. Run performance validation:
```python
import time
from core.memory.reflect import reflect_daily

# Measure reflect performance
start = time.time()
result = reflect_daily()
duration = time.time() - start

print(f"Reflect duration: {duration:.2f}s")
print(f"PERF-002 (< 300s): {'PASS' if duration < 300 else 'FAIL'}")
print(f"Result: {result}")
```

4. Validate database size:
```python
from core.memory.config import get_config
import os

config = get_config()
db_path = config.memory_dir / "jarvis.db"

if db_path.exists():
    size_mb = os.path.getsize(db_path) / (1024 * 1024)
    print(f"Database size: {size_mb:.2f}MB")
    print(f"PERF-003 (< 500MB): {'PASS' if size_mb < 500 else 'FAIL'}")
```

5. Generate test summary:
```python
# Count test results
print("\n=== Phase 8 Test Summary ===")
print("REF-001: reflect_daily runs - VERIFIED")
print("REF-002: memory.md updated - VERIFIED")
print("REF-003: Entity summaries auto-update - VERIFIED")
print("REF-004: Preference evolution - VERIFIED")
print("REF-005: Log archival - VERIFIED")
print("REF-006: Weekly patterns - VERIFIED")
print("REF-007: Contradiction detection - VERIFIED")
print("PERF-002: < 5 min reflect - VERIFIED")
print("PERF-003: < 500MB database - VERIFIED")
```

Fix any failing tests before marking complete.
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -m pytest tests/integration/test_memory_reflect.py -v --tb=short 2>&1 | tail -20
```
  </verify>
  <done>
All Phase 8 integration tests pass. Performance requirements PERF-002 (<5 min) and PERF-003 (<500MB) validated. Scheduler integration verified.
  </done>
</task>

</tasks>

<verification>
All verification steps must pass:

1. Supervisor registers daily and weekly reflect jobs
2. Jobs have correct cron schedules (3 AM daily, 4 AM Sundays)
3. Integration tests exist for all Phase 8 requirements
4. All tests pass (REF-001 through REF-007, PERF-002, PERF-003)
5. reflect_daily() completes in <5 minutes
6. Database stays under 500MB
</verification>

<success_criteria>
- Daily reflect scheduled for 3 AM UTC with 5-minute timeout
- Weekly summary scheduled for Sundays 4 AM UTC with 10-minute timeout
- All 11 Phase 8 requirements verified by integration tests
- Performance targets met: <5 min reflect, <500MB database
- Kill switch (MEMORY_REFLECT_ENABLED) supports disabling
</success_criteria>

<output>
After completion, create `.planning/memory-integration/phases/08-reflect-intelligence/08-05-SUMMARY.md`
</output>
