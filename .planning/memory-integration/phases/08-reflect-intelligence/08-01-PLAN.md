---
phase: 08-reflect-intelligence
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - core/memory/reflect.py
  - core/memory/summarize.py
  - core/memory/__init__.py
autonomous: true

must_haves:
  truths:
    - "reflect_daily() function exists and can be called"
    - "synthesize_daily_facts() uses Claude API to produce insights"
    - "reflect_state.json tracks last run time and stats"
    - "memory.md gets daily reflection sections appended"
  artifacts:
    - path: "core/memory/reflect.py"
      provides: "Daily reflection orchestration"
      min_lines: 150
      exports: ["reflect_daily"]
    - path: "core/memory/summarize.py"
      provides: "LLM-based fact synthesis"
      min_lines: 80
      exports: ["synthesize_daily_facts", "synthesize_entity_insights"]
  key_links:
    - from: "core/memory/reflect.py"
      to: "core/memory/summarize.py"
      via: "import synthesize_daily_facts"
      pattern: "from.*summarize.*import.*synthesize"
    - from: "core/memory/reflect.py"
      to: "core/memory/database.py"
      via: "get_db() for fact retrieval"
      pattern: "get_db\\(\\)"
---

<objective>
Create the core reflection infrastructure: `reflect.py` for daily orchestration and `summarize.py` for LLM-powered fact synthesis.

Purpose: Enable Jarvis to autonomously consolidate 24 hours of raw facts into durable knowledge using recursive summarization (MemGPT pattern).

Output:
- `core/memory/reflect.py` with reflect_daily() entry point and helper functions
- `core/memory/summarize.py` with Claude-powered synthesis
- reflect_state.json state tracking
- Daily reflection sections in memory.md
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/memory-integration/PROJECT.md
@.planning/memory-integration/ROADMAP.md
@.planning/memory-integration/STATE.md
@.planning/memory-integration/phases/08-reflect-intelligence/08-RESEARCH.md
@.planning/memory-integration/phases/07-retain-recall-functions/07-01-SUMMARY.md
@core/memory/database.py
@core/memory/config.py
@core/async_utils.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LLM synthesis module</name>
  <files>core/memory/summarize.py</files>
  <action>
Create `core/memory/summarize.py` with:

1. **synthesize_daily_facts(facts: List[Dict]) -> str**
   - Input: List of fact dicts with keys: id, content, context, source, timestamp, confidence, entities
   - Group facts by source for context organization
   - Build prompt that asks Claude 3.5 Sonnet to:
     - Synthesize TOP 5 most important facts to remember long-term
     - Focus on: trade outcomes, user preferences, token patterns, strategic insights, notable events
     - Use confidence markers: HIGH (objectively verified), MEDIUM (observed pattern), LOW (single occurrence)
     - Cite timestamps for each insight
   - Use temperature=0.3 for factual synthesis
   - Return synthesized markdown text
   - Handle empty facts list gracefully (return "No facts to synthesize")

2. **synthesize_entity_insights(entity_name: str, entity_type: str, facts: List[Dict]) -> str**
   - Input: Entity info and related facts
   - Build prompt asking Claude to produce:
     - Performance summary (if applicable - win rate, avg PnL, success patterns)
     - Behavioral patterns (what works, what fails)
     - Recent trends (changes in last 7 days)
     - Confidence assessment (how reliable is this data?)
   - Return 3-5 bullet points of actionable insights
   - Use temperature=0.3

3. Import anthropic client, handle API errors gracefully with logging

Example synthesis prompt structure:
```python
prompt = f"""You are Jarvis, reviewing yesterday's memory to extract key learnings.

Yesterday's facts organized by source:
{context_text}

Synthesize the TOP 5 most important facts...
"""
```

Use Claude model: "claude-3-5-sonnet-20241022"
Max tokens: 2000 for daily, 1000 for entity

DO NOT use hardcoded API keys - use anthropic.Anthropic() which reads from env.
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -c "from core.memory.summarize import synthesize_daily_facts, synthesize_entity_insights; print('Imports OK')"
```
  </verify>
  <done>
synthesize_daily_facts() and synthesize_entity_insights() exist and are importable. Functions handle empty input gracefully.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create core reflect module</name>
  <files>core/memory/reflect.py, core/memory/__init__.py</files>
  <action>
Create `core/memory/reflect.py` with:

1. **reflect_daily() -> Dict[str, Any]**
   - Main entry point for daily reflection
   - Calculate yesterday's time boundaries (00:00:00 to 23:59:59 UTC)
   - Query facts from yesterday using get_db()
   - If no facts, return early with {status: "skipped", reason: "no facts"}
   - Call synthesize_daily_facts() to get synthesis
   - Append synthesis to memory.md with section header:
     ```markdown
     ## Reflection: YYYY-MM-DD

     {synthesis}

     _Synthesized from N facts_

     ---
     ```
   - Store synthesis as a meta-fact with:
     - content: synthesis text
     - context: "daily_reflection"
     - source: "reflect_engine"
     - confidence: 0.9
   - Update reflect_state.json with:
     - last_reflect_time: ISO timestamp
     - facts_processed: count
     - duration_seconds: elapsed time
   - Return stats dict: {status: "completed", facts_processed: N, duration_seconds: X}
   - Log start/completion with timing

2. **get_reflect_state() -> Dict[str, Any]**
   - Load and return reflect_state.json from ~/.lifeos/memory/
   - Return empty dict if file doesn't exist

3. **save_reflect_state(state: Dict[str, Any])**
   - Save state to reflect_state.json
   - Create parent directory if needed

4. Use existing imports:
   - from core.memory.database import get_db
   - from core.memory.config import get_config
   - from core.memory.summarize import synthesize_daily_facts
   - from core.memory.retain import retain_fact

5. Add logging throughout for observability

Update `core/memory/__init__.py` to export:
- reflect_daily
- get_reflect_state

IMPORTANT: Use datetime.utcnow() for all timestamps (not local time).
IMPORTANT: Ensure memory.md file exists before appending (create with header if missing).
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
# Verify imports
python -c "from core.memory import reflect_daily, get_reflect_state; print('Imports OK')"

# Verify reflect module structure
python -c "
from core.memory.reflect import reflect_daily, get_reflect_state, save_reflect_state
import inspect
sig = inspect.signature(reflect_daily)
print(f'reflect_daily signature: {sig}')
"
```
  </verify>
  <done>
reflect_daily() exists, is importable, and the reflect module has get_reflect_state() and save_reflect_state() helpers.
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify core reflection flow works end-to-end</name>
  <files>core/memory/reflect.py</files>
  <action>
Test the core reflection flow manually:

1. First, create a test fact in the database to ensure there's data:
```python
from core.memory.retain import retain_fact
from datetime import datetime

# Store a test fact
retain_fact(
    content="Test trade: KR8TIV +15% profit on bags.fm graduation",
    context="trade_outcome",
    source="treasury_trading",
    entities=["@KR8TIV"]
)
print("Test fact stored")
```

2. Then test reflect_daily() with a dry run:
```python
from core.memory.reflect import reflect_daily, get_reflect_state
import asyncio

# Run reflection (may skip if no yesterday facts)
result = reflect_daily()
print(f"Reflect result: {result}")

# Check state was saved
state = get_reflect_state()
print(f"Reflect state: {state}")
```

3. Verify memory.md was updated (if facts existed):
```python
from core.memory.config import get_config
config = get_config()
memory_path = config.memory_dir / "memory.md"
if memory_path.exists():
    with open(memory_path, 'r') as f:
        content = f.read()
    print(f"memory.md size: {len(content)} chars")
    print(f"Has reflection section: {'## Reflection:' in content}")
```

If reflect_daily() fails due to no yesterday facts, that's expected behavior - log the skip reason.

Fix any issues found during testing before marking complete.
  </action>
  <verify>
```bash
cd c:/Users/lucid/OneDrive/Desktop/Projects/Jarvis
python -c "
from core.memory.reflect import reflect_daily
result = reflect_daily()
print(f'Status: {result.get(\"status\", \"unknown\")}')
assert 'status' in result, 'Missing status in result'
print('Core reflect flow verified')
"
```
  </verify>
  <done>
reflect_daily() executes without errors. Returns proper status dict. If no facts, returns {status: "skipped", reason: "no facts"}. If facts exist, synthesizes and appends to memory.md.
  </done>
</task>

</tasks>

<verification>
All verification steps must pass:

1. `core/memory/summarize.py` exists with synthesize functions
2. `core/memory/reflect.py` exists with reflect_daily()
3. Both modules are importable from `core.memory`
4. reflect_daily() returns a dict with "status" key
5. reflect_state.json is created/updated after successful run
</verification>

<success_criteria>
- synthesize_daily_facts() uses Claude 3.5 Sonnet for LLM synthesis
- reflect_daily() orchestrates the full daily reflection flow
- memory.md gets reflection sections appended (when facts exist)
- reflect_state.json tracks execution metadata
- All functions handle edge cases (no facts, API errors) gracefully
</success_criteria>

<output>
After completion, create `.planning/memory-integration/phases/08-reflect-intelligence/08-01-SUMMARY.md`
</output>
