---
phase: 1
plan: 1
wave: 1
name: Database Consolidation & Optimization
status: pending
created: 2026-01-24
---

# Phase 1.1: Database Consolidation & Optimization

**Goal:** Consolidate 28+ SQLite databases into 3 databases max (core, analytics, cache)

**Requirements:** REQ-001
**Priority:** P0
**Estimated Effort:** 2-3 weeks

---

## Problem Statement

Current state (from CONCERNS.md):
- 28+ separate SQLite databases identified
- Data fragmentation across multiple DBs
- No atomic cross-DB transactions
- High memory overhead (multiple connection pools)
- Lock contention issues
- Complex backup requirements
- Slow queries (cannot JOIN across DBs)

**Critical Impact:**
- Slower performance
- Data consistency risks
- Maintenance burden

---

## Solution Design

### Target Architecture

**Three Consolidated Databases:**

1. **jarvis_core.db** - Main application data (hot path)
   - Users & authentication
   - Trades & positions
   - Orders & execution history
   - Bot configurations
   - Token metadata cache

2. **jarvis_analytics.db** - Metrics, logs, memory (warm path)
   - LLM costs & usage
   - Performance metrics
   - Trading analytics
   - Sentiment data
   - AI memory/learnings
   - Health checks

3. **jarvis_cache.db** - Temporary/ephemeral data (cold path)
   - Rate limiter state
   - Session data
   - API response cache
   - WebSocket subscriptions
   - Can be cleared/rebuilt

### Migration Strategy

**Phase 1A: Analysis & Schema Design**
1. Map all 28 databases to target schemas
2. Identify foreign key relationships
3. Design unified schema for each consolidated DB
4. Create migration plan with rollback

**Phase 1B: Staged Migration**
1. Create consolidated DB schemas
2. Migrate data in batches (with verification)
3. Run dual-write period (old + new DBs)
4. Switch reads to new DBs
5. Decommission old DBs

**Phase 1C: Connection Pool Optimization**
1. Standardize connection pooling
2. Add pool metrics
3. Optimize pool sizes
4. Health check optimization

---

## Implementation Plan

### Task 1: Database Inventory & Analysis
**Owner:** kraken agent
**Effort:** 2 days

**Steps:**
1. List all 28+ databases with sizes and schemas
2. Run `PRAGMA table_info` on each table
3. Identify relationships (FK constraints, JOIN patterns in code)
4. Create database dependency graph
5. Map tables to target databases (core/analytics/cache)

**Deliverables:**
- `database_inventory.md` - Full list with schemas
- `dependency_graph.png` - Visual relationship map
- `migration_mapping.csv` - Table → Target DB mapping

**Verification:**
- All 28+ databases documented
- All tables mapped to target DB
- No orphaned tables

---

### Task 2: Unified Schema Design
**Owner:** kraken agent
**Effort:** 3 days

**Steps:**
1. Design `jarvis_core.db` schema
   - users table
   - trades table
   - positions table
   - orders table
   - bot_config table
   - token_metadata table
2. Design `jarvis_analytics.db` schema
   - llm_costs table
   - metrics table
   - sentiment table
   - ai_memory table
   - health_checks table
3. Design `jarvis_cache.db` schema
   - rate_limiter table
   - session_cache table
   - api_cache table
   - ws_subscriptions table
4. Add proper indexes for performance
5. Define foreign keys and constraints

**Deliverables:**
- `jarvis_core_schema.sql`
- `jarvis_analytics_schema.sql`
- `jarvis_cache_schema.sql`
- `schema_comparison.md` (old vs new)

**Verification:**
- Schemas support all existing use cases
- No data loss in mapping
- Performance maintained or improved

---

### Task 3: Migration Scripts with Rollback
**Owner:** kraken agent
**Effort:** 4 days

**Steps:**
1. Create migration scripts for each database
   - `migrate_core.py`
   - `migrate_analytics.py`
   - `migrate_cache.py`
2. Add data validation (checksums, row counts)
3. Create rollback scripts
4. Add progress logging
5. Test on copy of production data

**Deliverables:**
- `scripts/db_migration/migrate_core.py`
- `scripts/db_migration/migrate_analytics.py`
- `scripts/db_migration/migrate_cache.py`
- `scripts/db_migration/rollback.py`
- `scripts/db_migration/validate_migration.py`

**Verification:**
- Migration scripts tested on dev copy
- Rollback scripts work
- Zero data loss confirmed
- All validation checks pass

---

### Task 4: Execute Migration (Staged Rollout)
**Owner:** kraken agent
**Effort:** 3 days

**Steps:**
1. **Stage 1:** Analytics DB migration (low risk)
   - Run migration
   - Validate data
   - Switch analytics queries to new DB
   - Monitor for 24 hours

2. **Stage 2:** Cache DB migration (zero risk - can rebuild)
   - Clear old cache
   - Create new cache DB
   - Switch cache writes to new DB

3. **Stage 3:** Core DB migration (high risk - careful!)
   - Enable dual-write (old + new DBs)
   - Run migration
   - Validate data thoroughly
   - Switch reads to new DB
   - Monitor for 48 hours
   - Disable dual-write
   - Archive old DBs (don't delete yet!)

**Deliverables:**
- All data migrated to 3 consolidated DBs
- Old databases archived (not deleted)
- Validation reports for each stage

**Verification:**
- ≤3 total databases operational
- All queries work
- No data loss
- Performance maintained or improved

---

### Task 5: Connection Pool Standardization
**Owner:** kraken agent
**Effort:** 2 days

**Steps:**
1. Review all connection pool implementations:
   - `core/db/pool.py`
   - `core/db_connection_manager.py`
   - `bots/treasury/database.py`
   - Others (288+ files with DB imports)
2. Create unified connection pool manager
   - `core/db/unified_pool.py`
3. Replace all old pool code with unified version
4. Add pool metrics (connections, waits, errors)
5. Optimize pool sizes based on usage patterns

**Deliverables:**
- `core/db/unified_pool.py` - Standardized pool
- All 288+ DB imports updated
- Pool metrics dashboard

**Verification:**
- Single connection pool implementation
- <20% reduction in memory usage
- Pool metrics available in monitoring

---

### Task 6: Code Refactoring (DB Imports)
**Owner:** kraken agent
**Effort:** 3 days

**Steps:**
1. Update all 288+ files importing database code
2. Replace old DB paths with new consolidated paths
3. Update all queries to new table names
4. Add migration guide for developers
5. Run full test suite

**Deliverables:**
- All 288+ files updated
- Developer migration guide
- All tests passing

**Verification:**
- No references to old databases
- All queries work with new schemas
- Test suite passes

---

### Task 7: Performance Testing & Optimization
**Owner:** arbiter agent
**Effort:** 2 days

**Steps:**
1. Run baseline performance tests (before migration)
2. Run performance tests (after migration)
3. Compare latencies (should be same or better)
4. Identify any regressions
5. Optimize slow queries
6. Add database indexes where needed

**Deliverables:**
- Performance comparison report
- List of optimizations applied
- Query execution plan analysis

**Verification:**
- <500ms p95 latency for critical queries
- No performance regressions
- Atomic transactions working across related data

---

### Task 8: Integration Testing
**Owner:** arbiter agent
**Effort:** 2 days

**Steps:**
1. Test all critical flows end-to-end:
   - Trade execution flow
   - Position management
   - User authentication
   - Analytics querying
   - Cache operations
2. Test concurrent operations
3. Test failure scenarios (DB locked, disk full, etc.)
4. Verify rollback procedures

**Deliverables:**
- Integration test suite (100+ test cases)
- Failure scenario test results
- Rollback verification report

**Verification:**
- All critical flows work
- Concurrent operations succeed
- Rollback procedures verified

---

### Task 9: Documentation & Cleanup
**Owner:** scribe agent
**Effort:** 1 day

**Steps:**
1. Document new database architecture
2. Update developer docs
3. Create operations runbook
4. Archive old databases (backup to S3/cloud)
5. Clean up unused DB files

**Deliverables:**
- `docs/database_architecture.md`
- `docs/operations_runbook.md`
- Developer migration guide updated
- Old DBs archived

**Verification:**
- Documentation complete
- Old DBs safely archived
- Cleanup complete

---

## Success Criteria

- [ ] ≤3 total databases operational (jarvis_core, jarvis_analytics, jarvis_cache)
- [ ] Zero data loss during migration (verified via checksums)
- [ ] All existing functionality works (100% test pass rate)
- [ ] Atomic transactions possible across related data
- [ ] <20% reduction in memory usage (measured)
- [ ] <500ms p95 latency for critical queries
- [ ] Single standardized connection pool
- [ ] All 288+ DB imports updated
- [ ] Rollback procedures verified
- [ ] Documentation complete

---

## Risks & Mitigation

| Risk | Probability | Impact | Mitigation |
|------|------------|--------|------------|
| Data loss during migration | Low | Critical | Checksums, row counts, thorough validation, rollback scripts |
| Performance regression | Medium | High | Baseline tests, optimization phase, indexes |
| Migration breaks live bots | Medium | Critical | Staged rollout, dual-write period, 24-48h monitoring |
| Rollback fails | Low | Critical | Test rollback on dev data, validate scripts |
| Code refactoring introduces bugs | Medium | High | Full test suite, gradual rollout, feature flags |

---

## Dependencies

**Blockers:** None (can start immediately)

**Parallel Work:** Can run alongside Phase 2 (Demo Bot Fixes)

---

## Timeline

```
Week 1:
├─ Task 1: DB Inventory & Analysis (2 days)
├─ Task 2: Schema Design (3 days - parallel with Task 1)
└─ Task 3: Migration Scripts (start)

Week 2:
├─ Task 3: Migration Scripts (finish)
├─ Task 4: Staged Migration
│  ├─ Stage 1: Analytics (1 day)
│  ├─ Stage 2: Cache (1 day)
│  └─ Stage 3: Core (1 day + monitoring)

Week 3:
├─ Task 5: Connection Pool Standardization (2 days)
├─ Task 6: Code Refactoring (3 days)
├─ Task 7: Performance Testing (2 days - parallel)
├─ Task 8: Integration Testing (2 days - parallel)
└─ Task 9: Documentation (1 day)
```

**Total:** 2-3 weeks (aggressive, with parallel work)

---

## Verification Steps

After completion:
1. Run `ls data/*.db` - should see ≤3 databases
2. Run full test suite - 100% pass rate
3. Check memory usage - <20% reduction
4. Run performance tests - no regressions
5. Verify atomic transactions - test cross-table operations
6. Check monitoring - pool metrics available

---

## Next Phase

After Phase 1 complete → Continue Phase 2 (Demo Bot Fixes) or start Phase 3 (Vibe Command)

---

**Plan Version:** 1.0
**Created:** 2026-01-24
**Status:** Pending Execution
**Ready to Execute:** Yes (no blockers)
