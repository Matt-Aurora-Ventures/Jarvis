---
phase: 01-database-consolidation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - data/jarvis_analytics.db
  - data/jarvis_cache.db
  - scripts/db_consolidation_migrate.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "jarvis_analytics.db contains all LLM cost records from llm_costs.db"
    - "jarvis_analytics.db contains all metrics from metrics.db"
    - "jarvis_cache.db contains all rate limit data from rate_limiter.db"
    - "Row counts match between legacy and consolidated databases"
  artifacts:
    - path: "data/jarvis_analytics.db"
      provides: "Analytics data migrated"
      min_records: 19
    - path: "data/jarvis_cache.db"
      provides: "Cache data migrated"
      min_records: 5
    - path: "scripts/db_consolidation_migrate.py"
      provides: "Migration script with analytics/cache support"
      contains: "migrate_analytics"
  key_links:
    - from: "scripts/db_consolidation_migrate.py"
      to: "data/jarvis_analytics.db"
      via: "data migration"
      pattern: "INSERT INTO llm_usage|metrics_1m"
    - from: "scripts/db_consolidation_migrate.py"
      to: "data/jarvis_cache.db"
      via: "data migration"
      pattern: "INSERT INTO rate_configs|cache_entries"
---

<objective>
Complete the data migration by moving analytics and cache data from legacy databases to consolidated databases.

Purpose: Phase 1 verification found jarvis_analytics.db and jarvis_cache.db have schemas but no data. This plan closes that gap by executing the full migration.

Output: Fully populated jarvis_analytics.db and jarvis_cache.db with all historical data intact.
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-database-consolidation/01-VERIFICATION.md
@.planning/phases/01-database-consolidation/01-01-SUMMARY.md
@scripts/db_consolidation_migrate.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify migration script analytics support</name>
  <files>scripts/db_consolidation_migrate.py</files>
  <action>
Review the migration script to confirm it has:
1. Analytics database migration functions (migrate_analytics, migrate_llm_costs, migrate_metrics)
2. Cache database migration functions (migrate_cache, migrate_rate_limiter)
3. Validation logic to compare row counts between legacy and consolidated

If missing or incomplete, update the migration script to:
- Add migrate_analytics_data() function that:
  - Migrates llm_usage, llm_daily_stats, budget_alerts from data/llm_costs.db
  - Migrates metrics_1m, metrics_1h, alert_history from data/metrics.db
  - Migrates daily_stats, treasury_stats, trade_learnings from their sources
- Add migrate_cache_data() function that:
  - Migrates rate_configs, request_log, limit_stats from data/rate_limiter.db
  - Migrates cache_entries from data/file_cache.db
  - Migrates kv_entries, bot_state, last_actions from their sources
- Add validation checks to compare row counts and report any discrepancies

Gap reason: Verification found analytics/cache DBs empty with 0 records.
  </action>
  <verify>grep "migrate_analytics\|migrate_cache" scripts/db_consolidation_migrate.py</verify>
  <done>Migration script has functions for analytics and cache migration with validation</done>
</task>

<task type="auto">
  <name>Task 2: Execute analytics and cache migration</name>
  <files>data/jarvis_analytics.db, data/jarvis_cache.db</files>
  <action>
Run the migration script to populate analytics and cache databases:

1. First, run in dry-run mode to see what will be migrated:
   ```bash
   cd C:\Users\lucid\OneDrive\Desktop\Projects\Jarvis
   python scripts/db_consolidation_migrate.py --dry-run --analytics --cache
   ```

2. Review the dry-run output for:
   - Number of rows to migrate from llm_costs.db
   - Number of rows to migrate from metrics.db
   - Number of rows to migrate from rate_limiter.db
   - Number of rows to migrate from file_cache.db

3. Execute the actual migration:
   ```bash
   python scripts/db_consolidation_migrate.py --analytics --cache
   ```

4. Verify row counts after migration:
   ```bash
   # Check analytics DB
   sqlite3 data/jarvis_analytics.db "SELECT COUNT(*) FROM llm_usage; SELECT COUNT(*) FROM metrics_1m; SELECT COUNT(*) FROM daily_stats;"

   # Check cache DB
   sqlite3 data/jarvis_cache.db "SELECT COUNT(*) FROM rate_configs; SELECT COUNT(*) FROM cache_entries; SELECT COUNT(*) FROM request_log;"
   ```

Expected outcome based on dry-run test in 01-01-SUMMARY:
- 19 LLM usage records
- 1 LLM daily stats record
- 5 rate limit configs
- Additional metrics and cache entries as discovered

Gap items addressed:
- "Verify complete data migration (not just schema creation)"
- "Validate row counts match between legacy and consolidated"
- "Migrate analytics data (llm_costs, metrics)"
- "Migrate cache data (rate_limiter, sessions)"
  </action>
  <verify>sqlite3 data/jarvis_analytics.db "SELECT COUNT(*) FROM llm_usage" && sqlite3 data/jarvis_cache.db "SELECT COUNT(*) FROM rate_configs"</verify>
  <done>Analytics DB has ≥19 llm_usage records, cache DB has ≥5 rate_configs, row counts match dry-run predictions</done>
</task>

<task type="auto">
  <name>Task 3: Generate migration validation report</name>
  <files>.planning/phases/01-database-consolidation/01-02-MIGRATION-REPORT.md</files>
  <action>
Create a migration validation report documenting:

1. **Pre-migration state**:
   - Row counts from legacy databases (llm_costs.db, metrics.db, rate_limiter.db, file_cache.db)
   - Database file sizes before migration

2. **Migration execution**:
   - Timestamp of migration
   - Tables migrated
   - Rows migrated per table
   - Any errors or warnings

3. **Post-migration state**:
   - Row counts in consolidated databases
   - Database file sizes after migration
   - Validation checks (row count comparison)

4. **Data integrity checks**:
   - Compare sample records between legacy and consolidated
   - Verify foreign key relationships
   - Check for data loss or duplication

5. **Success criteria verification**:
   - ✓/✗ All analytics data migrated
   - ✓/✗ All cache data migrated
   - ✓/✗ Row counts match
   - ✓/✗ No data loss

Format as structured markdown with tables for easy verification.

Save to: .planning/phases/01-database-consolidation/01-02-MIGRATION-REPORT.md
  </action>
  <verify>test -f .planning/phases/01-database-consolidation/01-02-MIGRATION-REPORT.md</verify>
  <done>Migration report exists with pre/post migration row counts and validation results</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. **Data presence check**:
   ```bash
   # Analytics database should have data
   sqlite3 data/jarvis_analytics.db "SELECT COUNT(*) as llm_records FROM llm_usage; SELECT COUNT(*) as metric_records FROM metrics_1m;"

   # Cache database should have data
   sqlite3 data/jarvis_cache.db "SELECT COUNT(*) as rate_configs FROM rate_configs; SELECT COUNT(*) as cache_entries FROM cache_entries;"
   ```

2. **Row count validation**:
   - Compare row counts in migration report
   - Legacy DB counts should match consolidated DB counts
   - No data loss during migration

3. **File size check**:
   ```bash
   ls -lh data/jarvis_analytics.db data/jarvis_cache.db
   ```
   Both should be >0KB with substantive data

4. **Schema integrity**:
   ```bash
   sqlite3 data/jarvis_analytics.db ".schema llm_usage"
   sqlite3 data/jarvis_cache.db ".schema rate_configs"
   ```
   Tables should have proper columns and indexes
</verification>

<success_criteria>
- jarvis_analytics.db contains ≥19 llm_usage records (verified via SELECT COUNT)
- jarvis_analytics.db contains metrics data from metrics.db
- jarvis_cache.db contains ≥5 rate_configs (verified via SELECT COUNT)
- jarvis_cache.db contains cache data from file_cache.db
- Migration report shows 0 data loss
- Row counts match between legacy and consolidated databases
- All validation checks pass
</success_criteria>

<output>
After completion, create `.planning/phases/01-database-consolidation/01-02-SUMMARY.md` with:
- Tasks executed and outcomes
- Row counts migrated
- Validation results
- Any issues encountered and resolutions
</output>
