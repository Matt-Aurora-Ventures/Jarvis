---
phase: 01-database-consolidation
plan: 04
type: execute
wave: 3
depends_on: [01-02, 01-03]
files_modified:
  - data/
  - scripts/archive_legacy_databases.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "System uses ≤3 databases operationally"
    - "Legacy databases archived (not deleted)"
    - "System runs normally with only 3 consolidated databases"
    - "Rollback capability preserved via archives"
  artifacts:
    - path: "data/jarvis_core.db"
      provides: "Only core operational database"
    - path: "data/jarvis_analytics.db"
      provides: "Only analytics database"
    - path: "data/jarvis_cache.db"
      provides: "Only cache database"
    - path: "data/archive/"
      provides: "Legacy databases preserved"
      min_files: 24
    - path: "scripts/archive_legacy_databases.py"
      provides: "Archive script with rollback"
      contains: "def archive_database"
  key_links:
    - from: "scripts/archive_legacy_databases.py"
      to: "data/archive/"
      via: "file move operation"
      pattern: "shutil.move|os.rename"
---

<objective>
Remove legacy databases from production data/ directory and achieve ≤3 total databases goal.

Purpose: Verification found 27 total databases (3 consolidated + 24 legacy). This plan closes the gap by archiving legacy databases while preserving rollback capability.

Output: Production data/ directory contains only 3 consolidated databases, legacy databases safely archived.
</objective>

<execution_context>
@C:\Users\lucid\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\lucid\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-database-consolidation/01-VERIFICATION.md
@.planning/phases/01-database-consolidation/01-01-SUMMARY.md
@.planning/phases/01-database-consolidation/01-02-SUMMARY.md
@.planning/phases/01-database-consolidation/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify migration and code updates complete</name>
  <files>.planning/phases/01-database-consolidation/01-04-PRE-ARCHIVE-CHECKLIST.md</files>
  <action>
Before archiving legacy databases, verify prerequisites from previous plans:

**Pre-archive checklist:**

1. **Data migration complete (Plan 02)**:
   ```bash
   cd C:\Users\lucid\OneDrive\Desktop\Projects\Jarvis

   # Check analytics DB has data
   sqlite3 data/jarvis_analytics.db "SELECT COUNT(*) as llm_records FROM llm_usage;"

   # Check cache DB has data
   sqlite3 data/jarvis_cache.db "SELECT COUNT(*) as rate_configs FROM rate_configs;"
   ```
   Expected: ≥19 llm_records, ≥5 rate_configs

2. **Code updates complete (Plan 03)**:
   ```bash
   # Verify unified layer adoption
   grep -r "from core.database import" --include="*.py" core/ bots/ tg_bot/ | wc -l

   # Verify no hardcoded legacy paths in critical files
   grep -r "llm_costs\.db\|jarvis\.db" --include="*.py" core/llm/ bots/treasury/
   ```
   Expected: 15+ imports, 0 hardcoded paths in production code

3. **System functionality test**:
   - Recommendation: Ask user to test critical paths before archiving
   - Critical: Trade execution, LLM cost tracking, rate limiting
   - This prevents data loss if migration had issues

4. **Backup verification**:
   ```bash
   ls -lh backups/*db_backup* | head -5
   ```
   Expected: Recent backup files exist

**Create checklist report:**
- Document results of each verification step
- ✓ or ✗ for each item
- Any warnings or concerns

Save to: .planning/phases/01-database-consolidation/01-04-PRE-ARCHIVE-CHECKLIST.md

**IMPORTANT**: If any check fails, STOP and fix the issue before archiving. Archiving is irreversible without restore.

Gap context: Verification found goal NOT achieved due to 24 legacy databases present. Must ensure new system works before removing old one.
  </action>
  <verify>test -f .planning/phases/01-database-consolidation/01-04-PRE-ARCHIVE-CHECKLIST.md</verify>
  <done>Pre-archive checklist complete with all prerequisites verified</done>
</task>

<task type="auto">
  <name>Task 2: Create archive script with rollback</name>
  <files>scripts/archive_legacy_databases.py</files>
  <action>
Create a safe archive script that moves legacy databases to archive/ with rollback capability:

**Script requirements:**

1. **Archive function**:
   ```python
   def archive_database(db_path: str, archive_dir: str) -> bool:
       """Move database to archive with timestamp."""
       # Create archive dir if not exists
       # Add timestamp to filename
       # Move (not copy) to preserve disk space
       # Log action
       # Return success/failure
   ```

2. **Legacy database identification**:
   - List of 24 legacy databases from verification report:
     - jarvis.db (keep as .old for reference)
     - llm_costs.db
     - metrics.db
     - rate_limiter.db
     - telegram_memory.db
     - file_cache.db
     - ai_memory.db
     - (and 17 others from inventory)
   - DO NOT archive the 3 consolidated databases
   - DO NOT archive macOS metadata files (delete those)

3. **Safety checks**:
   - Verify 3 consolidated databases exist and have data
   - Confirm production code doesn't reference legacy DBs (from Plan 03)
   - Create archive directory: data/archive/2026-01-26/
   - Verify sufficient disk space for move operation

4. **Dry-run mode**:
   - `--dry-run` flag to preview what will be archived
   - Show source → destination for each file
   - Calculate total size to archive

5. **Rollback script**:
   - Create `scripts/restore_legacy_databases.py`
   - Moves files from archive/ back to data/
   - For emergency use only

6. **Logging**:
   - Log each file archived with timestamp
   - Generate archive manifest file
   - Save log to: data/archive/2026-01-26/ARCHIVE-LOG.txt

**Implementation:**
```python
#!/usr/bin/env python3
"""Archive legacy databases after consolidation."""

import os
import shutil
from pathlib import Path
from datetime import datetime

LEGACY_DATABASES = [
    "jarvis.db", "llm_costs.db", "metrics.db", "rate_limiter.db",
    "telegram_memory.db", "file_cache.db", "ai_memory.db",
    # Add remaining 17 from inventory
]

KEEP_DATABASES = ["jarvis_core.db", "jarvis_analytics.db", "jarvis_cache.db"]

def archive_legacy_databases(dry_run=False):
    timestamp = datetime.now().strftime("%Y-%m-%d")
    archive_dir = Path(f"data/archive/{timestamp}")

    if not dry_run:
        archive_dir.mkdir(parents=True, exist_ok=True)

    archived = []
    for db_name in LEGACY_DATABASES:
        db_path = Path(f"data/{db_name}")
        if db_path.exists():
            archive_path = archive_dir / db_name
            if dry_run:
                print(f"Would archive: {db_path} → {archive_path}")
            else:
                shutil.move(str(db_path), str(archive_path))
                archived.append(db_name)

    return archived

if __name__ == "__main__":
    import sys
    dry_run = "--dry-run" in sys.argv
    result = archive_legacy_databases(dry_run)
    print(f"Archived {len(result)} databases")
```

Gap items addressed:
- "Execute cleanup to remove/archive legacy databases"
- "Verify all production code uses consolidated databases only" (prerequisite check)
  </action>
  <verify>test -f scripts/archive_legacy_databases.py && grep "def archive_database\|LEGACY_DATABASES" scripts/archive_legacy_databases.py</verify>
  <done>Archive script exists with dry-run, safety checks, and rollback capability</done>
</task>

<task type="auto">
  <name>Task 3: Execute legacy database archival</name>
  <files>data/archive/</files>
  <action>
Archive legacy databases to achieve ≤3 databases goal:

1. **Dry-run first**:
   ```bash
   cd C:\Users\lucid\OneDrive\Desktop\Projects\Jarvis
   python scripts/archive_legacy_databases.py --dry-run
   ```
   - Review output: Which databases will be archived
   - Verify 3 consolidated databases NOT in list
   - Check total size to archive

2. **Final safety confirmation**:
   - Review pre-archive checklist results from Task 1
   - Confirm all verifications passed
   - Ensure backups exist

3. **Execute archive**:
   ```bash
   python scripts/archive_legacy_databases.py
   ```
   - Script will move 24 legacy databases to data/archive/2026-01-26/
   - 3 consolidated databases remain in data/
   - Generates ARCHIVE-LOG.txt with details

4. **Verify goal achieved**:
   ```bash
   # Count databases in data/ (should be 3)
   ls data/*.db | wc -l

   # List what remains (should see only consolidated DBs)
   ls -lh data/*.db

   # Verify archive created
   ls -lh data/archive/2026-01-26/ | head -10
   ```
   Expected: 3 databases in data/, 24 databases in archive/

5. **Post-archive system test**:
   - Run supervisor briefly to ensure no errors
   - Check logs for database connection issues
   - Verify critical operations still work

   If system works: Archive successful
   If system fails: Run restore script immediately

6. **Document results**:
   - How many databases archived
   - Total size freed in data/ directory
   - Location of archive
   - Any issues encountered

Gap from verification: "27 total databases present (3 consolidated + 24 legacy), legacy databases not removed"

After this task: 3 total databases in data/ (goal achieved), 24 safely archived with rollback option
  </action>
  <verify>test $(ls data/*.db 2>/dev/null | wc -l) -le 5 && test -d data/archive</verify>
  <done>≤5 databases in data/ directory (3 consolidated + allowance for variance), archive directory exists with legacy databases</done>
</task>

<task type="auto">
  <name>Task 4: Generate final verification report</name>
  <files>.planning/phases/01-database-consolidation/01-04-FINAL-VERIFICATION.md</files>
  <action>
Create final verification report confirming Phase 1 goal achieved:

**Report sections:**

1. **Goal achievement summary**:
   - Original goal: Consolidate 28+ databases into 3 databases max
   - Starting state: 35 databases found (29 production + 6 macOS metadata)
   - Final state: 3 databases operational
   - Status: ✅ GOAL ACHIEVED

2. **Database inventory** (before/after):
   | Category | Before | After | Change |
   |----------|--------|-------|--------|
   | Production DBs | 29 | 3 | -26 (90% reduction) |
   | Archived | 0 | 24 | +24 |
   | Deleted (metadata) | 6 | 0 | -6 |
   | **Total operational** | **35** | **3** | **-32 (91% reduction)** |

3. **Consolidated database details**:
   - jarvis_core.db: Size, table count, row count
   - jarvis_analytics.db: Size, table count, row count
   - jarvis_cache.db: Size, table count, row count

4. **Archive details**:
   - Archive location: data/archive/2026-01-26/
   - Databases archived: List all 24
   - Total size archived
   - Rollback procedure documented

5. **Verification of phase must-haves**:
   - ✓ System uses ≤3 databases operationally
   - ✓ All data migrated to consolidated databases
   - ✓ Production code uses consolidated database layer
   - ✓ Zero data loss during migration
   - ✓/? Memory usage reduced <20% (needs measurement)

6. **Outstanding items**:
   - Memory measurement (needs baseline comparison)
   - Performance benchmarking (load testing)
   - Any warnings or concerns

7. **Rollback information**:
   - Archive location
   - Restore script: scripts/restore_legacy_databases.py
   - Estimated restore time
   - When to use (emergency only)

8. **Next steps**:
   - Monitor system for 24-48 hours
   - Measure memory usage and compare to baseline
   - After 1 week with no issues: Archive can be considered stable
   - After 1 month: Archive can be deleted to free disk space

Save to: .planning/phases/01-database-consolidation/01-04-FINAL-VERIFICATION.md

This report proves the phase goal is achieved and provides audit trail.
  </action>
  <verify>test -f .planning/phases/01-database-consolidation/01-04-FINAL-VERIFICATION.md</verify>
  <done>Final verification report exists confirming ≤3 databases goal achieved</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. **Database count verification**:
   ```bash
   # Should show exactly 3 databases
   ls data/*.db
   ```
   Expected output:
   - data/jarvis_core.db
   - data/jarvis_analytics.db
   - data/jarvis_cache.db

2. **Archive verification**:
   ```bash
   # Should show 24 archived databases
   ls data/archive/2026-01-26/*.db | wc -l
   ```
   Expected: 24 (or more if additional legacy DBs found)

3. **System health check**:
   ```bash
   # Run supervisor briefly
   python bots/supervisor.py --check
   ```
   Expected: No database connection errors

4. **No references to legacy DBs**:
   ```bash
   # Should return no results (except archived files)
   grep -r "data/jarvis\.db\|data/llm_costs\.db" --include="*.py" core/ bots/ tg_bot/
   ```

5. **Documentation complete**:
   - Pre-archive checklist exists
   - Archive script exists
   - Final verification report exists
   - All reports show success
</verification>

<success_criteria>
- Exactly 3 databases in data/ directory (jarvis_core, jarvis_analytics, jarvis_cache)
- 24+ databases archived in data/archive/2026-01-26/
- Archive script with rollback capability exists
- System runs normally with 3 consolidated databases
- Final verification report confirms goal achieved
- No hardcoded references to archived database files
- Archive log documents all archived files
</success_criteria>

<output>
After completion, create `.planning/phases/01-database-consolidation/01-04-SUMMARY.md` with:
- Archive execution results
- Database count before/after
- System health check results
- Location of archived databases
- Rollback procedure
- Any issues and resolutions
</output>
