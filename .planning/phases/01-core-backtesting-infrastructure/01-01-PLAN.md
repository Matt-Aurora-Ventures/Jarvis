---
phase: 01-core-backtesting-infrastructure
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [core/backtest/data_ingestion/coingecko.py, core/backtest/data_ingestion/tests/test_coingecko.py]
autonomous: true
requirements: [py-torch-suite]

must_haves:
  truths:
    - "Can fetch historical price, market cap, and volume data from CoinGecko"
    - "Data is correctly cached locally to prevent API rate limits"
    - "Data is correctly parsed into a pandas DataFrame"
  artifacts:
    - path: "core/backtest/data_ingestion/coingecko.py"
      provides: "Data fetching wrapper"
      exports: ["fetch_historical_data"]
  key_links: []
---

<objective>
Implement the CoinGecko Historical Data ingestion module.

Purpose: We need clean, reliable, and cached historical data from CoinGecko to train our PyTorch backtesting engine without constantly hitting the API's rate limits.
Output: Python module for downloading and caching `.parquet` or `.csv` files representing historical OHLCV data.
</objective>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-backtesting-infrastructure/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Scaffold Directory and Data Ingestion Wrapper</name>
  <files>core/backtest/data_ingestion/coingecko.py</files>
  <action>
    Create the `core/backtest/data_ingestion` directory structure.
    Write `coingecko.py` that implements a Class or function `fetch_historical_data(coin_id: str, days: int, currency="usd")`.
    Ensure the code checks for a local cache (e.g. `data/cache/{coin_id}_{days}.parquet`) before hitting the `https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart` endpoint.
    Use `pandas` to structure the returning `prices` and `total_volumes` data into a single DataFrame.
    Implement automatic sleep/retry logic specifically for HTTP 429 status codes.
  </action>
  <verify>Run a basic Python script that imports this function and verifies a DataFrame is returned.</verify>
  <done>Caching logic avoids redundant fetches and returns parsed dataframes.</done>
</task>

<task type="auto">
  <name>Task 2: Write tests for the CoinGecko wrapper</name>
  <files>core/backtest/data_ingestion/tests/test_coingecko.py</files>
  <action>
    Create unit tests using `pytest` that mock the `requests.get` call to ensure the wrapper parses correctly.
    Test the rate limit error handling specifically.
  </action>
  <verify>Run `pytest core/backtest/data_ingestion/tests`</verify>
  <done>All ingestion tests pass with mocked responses.</done>
</task>

</tasks>

<verification>
- [ ] `pytest core/backtest/data_ingestion` passes
- [ ] Pyright/mypy linting passes on the new files
- [ ] Script successfully fetches real data from CoinGecko when tested manually
</verification>

<success_criteria>
- The new ingestion files exist.
- Testing successfully mocks rate limits and standard responses.
- Historical data is correctly transformed into pandas DataFrames.
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-backtesting-infrastructure/01-01-SUMMARY.md`
</output>
