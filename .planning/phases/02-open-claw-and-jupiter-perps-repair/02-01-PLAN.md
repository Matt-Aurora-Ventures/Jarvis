---
phase: 02-open-claw-and-jupiter-perps-repair
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [core/open_claw/sdk.py, core/open_claw/signals/engines.py, core/open_claw/signals/stats.py, core/open_claw/tests/test_engines.py]
autonomous: true
requirements: [open-claw-extension]

must_haves:
  truths:
    - "Bifurcated processing separates Macro policy envelope generation from Micro execution checks"
    - "Wilson Confidence Interval computation works correctly for discounting strategy scores."
    - "Open Claw logic does not touch keys or execute directly on chain."
  artifacts:
    - path: "core/open_claw/signals/engines.py"
      provides: "Macro and Micro engine abstractions"
      exports: ["MacroEngine", "MicroEngine", "breaking_news_check"]
    - path: "core/open_claw/signals/stats.py"
      provides: "Statistical thresholds"
      exports: ["wilson_lower_bound"]
  key_links: []
---

<objective>
Refactor and expose the Open Claw logic specifically utilizing the Bifurcated Intelligence Model and statistical confidence gates.

Purpose: Implement the required decoupled signal architecture. The Macro engine provides broad envelopes (bias, leverage limits) every few hours. The Micro engine parses fast streaming ticks against that envelope and performs dynamic statistical sampling (dTS / Wilson Intervals).
Output: Core packages in `core/open_claw/signals`.
</objective>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-open-claw-and-jupiter-perps-repair/02-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Build Statistical Gates (Wilson Score)</name>
  <files>core/open_claw/signals/stats.py</files>
  <action>
    Implement Wilson Confidence Interval bounds leveraging `scipy` or pure math if avoiding bulk dependencies.
    It must evaluate `wins` / `total` correctly to provide a conservative 95% lower-bound success metric.
    Add standard logic for Discounted Thompson Sampling state.
  </action>
  <verify>Run the script and output the wilson interval for 95 wins / 100 trials compared to 1 win / 1 trial.</verify>
  <done>Stats file outputs statistically sound probability boundaries to punish unproven heuristics.</done>
</task>

<task type="auto">
  <name>Task 2: Implement Micro and Macro Engines</name>
  <files>core/open_claw/signals/engines.py</files>
  <action>
    Implement the structured JSON schemas using `pydantic`. The output of the macro engine should be `PolicyEnvelope(bias, max_lev, validation_price)`.
    Build `async def breaking_news_check` utilizing standard prompt text passing to `x_ai` or mock string match wrapper ensuring it asks for `SAFE` or `DANGER`.
  </action>
  <verify>Run python to ensure parsing of mock policies loads correctly via Pydantic model validation.</verify>
  <done>Engine logic is separated, parsing is strongly typed, safety gate restricts trades on `DANGER`.</done>
</task>

<task type="auto">
  <name>Task 3: Expose Unified SDK</name>
  <files>core/open_claw/sdk.py</files>
  <action>
    Create the `OpenClawSDK` class which takes parameters and exposes a clean `evaluate()` pipe blending the engines and the stats gate. It throws appropriate internal exceptions when conditions are not met.
  </action>
  <verify>Create a unit test passing mock data ensuring the envelope boundary rejects invalid signals.</verify>
  <done>SDK runs safely without blockchain code references.</done>
</task>

</tasks>

<verification>
- [ ] Run Pytest or python interpreter on the module to ensure no syntax errors.
- [ ] Validate stats logic properly returns floats between 0.0 and 1.0.
</verification>

<success_criteria>
- The algorithmic components function autonomously as purely mathematical logic layers.
</success_criteria>

<output>
After completion, create `.planning/phases/02-open-claw-and-jupiter-perps-repair/02-01-SUMMARY.md`
</output>
